{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7352252,"sourceType":"datasetVersion","datasetId":4269831},{"sourceId":7356676,"sourceType":"datasetVersion","datasetId":4272812},{"sourceId":7366341,"sourceType":"datasetVersion","datasetId":4279471}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.utils import to_categorical\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-14T23:00:24.059274Z","iopub.execute_input":"2024-01-14T23:00:24.059744Z","iopub.status.idle":"2024-01-14T23:00:38.519090Z","shell.execute_reply.started":"2024-01-14T23:00:24.059709Z","shell.execute_reply":"2024-01-14T23:00:38.517896Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/dataset-wrist-filt/combined_wrist_filtered.pkl\"","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:01:02.796534Z","iopub.execute_input":"2024-01-14T23:01:02.797309Z","iopub.status.idle":"2024-01-14T23:01:02.802699Z","shell.execute_reply.started":"2024-01-14T23:01:02.797272Z","shell.execute_reply":"2024-01-14T23:01:02.801782Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df_wrist = pd.read_pickle(path)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:01:06.366916Z","iopub.execute_input":"2024-01-14T23:01:06.367953Z","iopub.status.idle":"2024-01-14T23:01:24.039259Z","shell.execute_reply.started":"2024-01-14T23:01:06.367917Z","shell.execute_reply":"2024-01-14T23:01:24.038187Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_wrist.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:17.907905Z","iopub.execute_input":"2024-01-14T23:02:17.908459Z","iopub.status.idle":"2024-01-14T23:02:17.941569Z","shell.execute_reply.started":"2024-01-14T23:02:17.908421Z","shell.execute_reply":"2024-01-14T23:02:17.940272Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         id      ACC_x      ACC_y      ACC_z         BVP       EDA       TEMP  \\\n214583  2.0  39.469502  27.912214  29.039982 -109.222518  1.637703  35.809887   \n214584  2.0  38.595181  27.796006  29.093324 -108.599068  1.637493  35.809884   \n214585  2.0  37.719606  27.683257  29.114913 -107.981064  1.637285  35.809882   \n214586  2.0  36.849917  27.575278  29.103982 -107.368689  1.637080  35.809879   \n214587  2.0  35.993018  27.473250  29.060322 -106.762018  1.636878  35.809876   \n\n        label  \n214583    1.0  \n214584    1.0  \n214585    1.0  \n214586    1.0  \n214587    1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ACC_x</th>\n      <th>ACC_y</th>\n      <th>ACC_z</th>\n      <th>BVP</th>\n      <th>EDA</th>\n      <th>TEMP</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>214583</th>\n      <td>2.0</td>\n      <td>39.469502</td>\n      <td>27.912214</td>\n      <td>29.039982</td>\n      <td>-109.222518</td>\n      <td>1.637703</td>\n      <td>35.809887</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>214584</th>\n      <td>2.0</td>\n      <td>38.595181</td>\n      <td>27.796006</td>\n      <td>29.093324</td>\n      <td>-108.599068</td>\n      <td>1.637493</td>\n      <td>35.809884</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>214585</th>\n      <td>2.0</td>\n      <td>37.719606</td>\n      <td>27.683257</td>\n      <td>29.114913</td>\n      <td>-107.981064</td>\n      <td>1.637285</td>\n      <td>35.809882</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>214586</th>\n      <td>2.0</td>\n      <td>36.849917</td>\n      <td>27.575278</td>\n      <td>29.103982</td>\n      <td>-107.368689</td>\n      <td>1.637080</td>\n      <td>35.809879</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>214587</th>\n      <td>2.0</td>\n      <td>35.993018</td>\n      <td>27.473250</td>\n      <td>29.060322</td>\n      <td>-106.762018</td>\n      <td>1.636878</td>\n      <td>35.809876</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_wrist.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T03:58:37.790094Z","iopub.execute_input":"2024-01-14T03:58:37.790867Z","iopub.status.idle":"2024-01-14T03:58:38.070880Z","shell.execute_reply.started":"2024-01-14T03:58:37.790812Z","shell.execute_reply":"2024-01-14T03:58:38.069895Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"id       0\nACC_x    0\nACC_y    0\nACC_z    0\nBVP      0\nEDA      0\nTEMP     0\nlabel    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_wrist.isna().any()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T03:58:48.327068Z","iopub.execute_input":"2024-01-14T03:58:48.327424Z","iopub.status.idle":"2024-01-14T03:58:48.513150Z","shell.execute_reply.started":"2024-01-14T03:58:48.327398Z","shell.execute_reply":"2024-01-14T03:58:48.512175Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"id       False\nACC_x    False\nACC_y    False\nACC_z    False\nBVP      False\nEDA      False\nTEMP     False\nlabel    False\ndtype: bool"},"metadata":{}}]},{"cell_type":"code","source":"df_wrist.groupby(['id', 'label']).count()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T03:59:01.198218Z","iopub.execute_input":"2024-01-14T03:59:01.198569Z","iopub.status.idle":"2024-01-14T03:59:03.213074Z","shell.execute_reply.started":"2024-01-14T03:59:01.198544Z","shell.execute_reply":"2024-01-14T03:59:03.212063Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             ACC_x   ACC_y   ACC_z     BVP     EDA    TEMP\nid   label                                                \n2.0  1.0    800800  800800  800800  800800  800800  800800\n     2.0    430500  430500  430500  430500  430500  430500\n     3.0    253400  253400  253400  253400  253400  253400\n3.0  1.0    798000  798000  798000  798000  798000  798000\n     2.0    448000  448000  448000  448000  448000  448000\n     3.0    262500  262500  262500  262500  262500  262500\n4.0  1.0    810601  810601  810601  810601  810601  810601\n     2.0    444500  444500  444500  444500  444500  444500\n     3.0    260400  260400  260400  260400  260400  260400\n5.0  1.0    838600  838600  838600  838600  838600  838600\n     2.0    451500  451500  451500  451500  451500  451500\n     3.0    261800  261800  261800  261800  261800  261800\n6.0  1.0    826000  826000  826000  826000  826000  826000\n     2.0    455000  455000  455000  455000  455000  455000\n     3.0    260400  260400  260400  260400  260400  260400\n7.0  1.0    830200  830200  830200  830200  830200  830200\n     2.0    448000  448000  448000  448000  448000  448000\n     3.0    260401  260401  260401  260401  260401  260401\n8.0  1.0    818300  818300  818300  818300  818300  818300\n     2.0    469000  469000  469000  469000  469000  469000\n     3.0    258999  258999  258999  258999  258999  258999\n9.0  1.0    826000  826000  826000  826000  826000  826000\n     2.0    451500  451500  451500  451500  451500  451500\n     3.0    260400  260400  260400  260400  260400  260400\n10.0 1.0    826000  826000  826000  826000  826000  826000\n     2.0    507500  507500  507500  507500  507500  507500\n     3.0    260400  260400  260400  260400  260400  260400\n11.0 1.0    826000  826000  826000  826000  826000  826000\n     2.0    476000  476000  476000  476000  476000  476000\n     3.0    257600  257600  257600  257600  257600  257600\n13.0 1.0    826001  826001  826001  826001  826001  826001\n     2.0    464800  464800  464800  464800  464800  464800\n     3.0    267400  267400  267400  267400  267400  267400\n14.0 1.0    826000  826000  826000  826000  826000  826000\n     2.0    472500  472500  472500  472500  472500  472500\n     3.0    260401  260401  260401  260401  260401  260401\n15.0 1.0    822500  822500  822500  822500  822500  822500\n     2.0    480200  480200  480200  480200  480200  480200\n     3.0    260400  260400  260400  260400  260400  260400\n16.0 1.0    826000  826000  826000  826000  826000  826000\n     2.0    471101  471101  471101  471101  471101  471101\n     3.0    257600  257600  257600  257600  257600  257600\n17.0 1.0    826700  826700  826700  826700  826700  826700\n     2.0    506100  506100  506100  506100  506100  506100\n     3.0    260400  260400  260400  260400  260400  260400","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>ACC_x</th>\n      <th>ACC_y</th>\n      <th>ACC_z</th>\n      <th>BVP</th>\n      <th>EDA</th>\n      <th>TEMP</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">2.0</th>\n      <th>1.0</th>\n      <td>800800</td>\n      <td>800800</td>\n      <td>800800</td>\n      <td>800800</td>\n      <td>800800</td>\n      <td>800800</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>430500</td>\n      <td>430500</td>\n      <td>430500</td>\n      <td>430500</td>\n      <td>430500</td>\n      <td>430500</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>253400</td>\n      <td>253400</td>\n      <td>253400</td>\n      <td>253400</td>\n      <td>253400</td>\n      <td>253400</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">3.0</th>\n      <th>1.0</th>\n      <td>798000</td>\n      <td>798000</td>\n      <td>798000</td>\n      <td>798000</td>\n      <td>798000</td>\n      <td>798000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>262500</td>\n      <td>262500</td>\n      <td>262500</td>\n      <td>262500</td>\n      <td>262500</td>\n      <td>262500</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">4.0</th>\n      <th>1.0</th>\n      <td>810601</td>\n      <td>810601</td>\n      <td>810601</td>\n      <td>810601</td>\n      <td>810601</td>\n      <td>810601</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>444500</td>\n      <td>444500</td>\n      <td>444500</td>\n      <td>444500</td>\n      <td>444500</td>\n      <td>444500</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">5.0</th>\n      <th>1.0</th>\n      <td>838600</td>\n      <td>838600</td>\n      <td>838600</td>\n      <td>838600</td>\n      <td>838600</td>\n      <td>838600</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>261800</td>\n      <td>261800</td>\n      <td>261800</td>\n      <td>261800</td>\n      <td>261800</td>\n      <td>261800</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">6.0</th>\n      <th>1.0</th>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>455000</td>\n      <td>455000</td>\n      <td>455000</td>\n      <td>455000</td>\n      <td>455000</td>\n      <td>455000</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">7.0</th>\n      <th>1.0</th>\n      <td>830200</td>\n      <td>830200</td>\n      <td>830200</td>\n      <td>830200</td>\n      <td>830200</td>\n      <td>830200</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n      <td>448000</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">8.0</th>\n      <th>1.0</th>\n      <td>818300</td>\n      <td>818300</td>\n      <td>818300</td>\n      <td>818300</td>\n      <td>818300</td>\n      <td>818300</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>469000</td>\n      <td>469000</td>\n      <td>469000</td>\n      <td>469000</td>\n      <td>469000</td>\n      <td>469000</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>258999</td>\n      <td>258999</td>\n      <td>258999</td>\n      <td>258999</td>\n      <td>258999</td>\n      <td>258999</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">9.0</th>\n      <th>1.0</th>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n      <td>451500</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">10.0</th>\n      <th>1.0</th>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>507500</td>\n      <td>507500</td>\n      <td>507500</td>\n      <td>507500</td>\n      <td>507500</td>\n      <td>507500</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">11.0</th>\n      <th>1.0</th>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>476000</td>\n      <td>476000</td>\n      <td>476000</td>\n      <td>476000</td>\n      <td>476000</td>\n      <td>476000</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">13.0</th>\n      <th>1.0</th>\n      <td>826001</td>\n      <td>826001</td>\n      <td>826001</td>\n      <td>826001</td>\n      <td>826001</td>\n      <td>826001</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>464800</td>\n      <td>464800</td>\n      <td>464800</td>\n      <td>464800</td>\n      <td>464800</td>\n      <td>464800</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>267400</td>\n      <td>267400</td>\n      <td>267400</td>\n      <td>267400</td>\n      <td>267400</td>\n      <td>267400</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">14.0</th>\n      <th>1.0</th>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>472500</td>\n      <td>472500</td>\n      <td>472500</td>\n      <td>472500</td>\n      <td>472500</td>\n      <td>472500</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n      <td>260401</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">15.0</th>\n      <th>1.0</th>\n      <td>822500</td>\n      <td>822500</td>\n      <td>822500</td>\n      <td>822500</td>\n      <td>822500</td>\n      <td>822500</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>480200</td>\n      <td>480200</td>\n      <td>480200</td>\n      <td>480200</td>\n      <td>480200</td>\n      <td>480200</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">16.0</th>\n      <th>1.0</th>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n      <td>826000</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>471101</td>\n      <td>471101</td>\n      <td>471101</td>\n      <td>471101</td>\n      <td>471101</td>\n      <td>471101</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n      <td>257600</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">17.0</th>\n      <th>1.0</th>\n      <td>826700</td>\n      <td>826700</td>\n      <td>826700</td>\n      <td>826700</td>\n      <td>826700</td>\n      <td>826700</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>506100</td>\n      <td>506100</td>\n      <td>506100</td>\n      <td>506100</td>\n      <td>506100</td>\n      <td>506100</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n      <td>260400</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Extraer features y labels\nX = df_wrist[['ACC_x', 'ACC_y', 'ACC_z', 'BVP', 'EDA', 'TEMP']].values\ny = df_wrist['label'].values\ny.dtype","metadata":{"execution":{"iopub.status.busy":"2024-01-14T16:00:53.311027Z","iopub.execute_input":"2024-01-14T16:00:53.312220Z","iopub.status.idle":"2024-01-14T16:00:53.524154Z","shell.execute_reply.started":"2024-01-14T16:00:53.312189Z","shell.execute_reply":"2024-01-14T16:00:53.523106Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"dtype('float64')"},"metadata":{}}]},{"cell_type":"code","source":"# Primero se converte la columna de tipo float a tipo categórico\ny = pd.Categorical(y)\ny.dtype","metadata":{"execution":{"iopub.status.busy":"2024-01-14T16:00:59.217597Z","iopub.execute_input":"2024-01-14T16:00:59.218504Z","iopub.status.idle":"2024-01-14T16:00:59.478591Z","shell.execute_reply.started":"2024-01-14T16:00:59.218469Z","shell.execute_reply":"2024-01-14T16:00:59.477550Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"CategoricalDtype(categories=[1.0, 2.0, 3.0], ordered=False)"},"metadata":{}}]},{"cell_type":"code","source":"# Crear un modelo CNN para clasificación binaria para los datos recopilados de muñeca\n# utilizando los parámetros que han salido mejores resultados de los datos de pecho\nsampling_rate = 700  # Hz\nwindow_time = 1  # segundos\nsequence_length = sampling_rate * window_time\nstep_size = sequence_length // 2\n\n# Crear segmentos con overlapping windows\nsegments = []\nlabels = []\nfor i in range(0, len(X) - sequence_length, step_size):\n    segment = X[i:i + sequence_length]\n    label = y[i + sequence_length - 1]  \n    segments.append(segment)\n    labels.append(label)\n\n# Convertir a vector \nX_segments = np.array(segments)\ny_segments = np.array(labels)\n\n# Clasificar label 1(fase neutral) y 3(diversión) a un grupo(no estrés) y label 2(estrés) a otro\ny_segments_binary = np.where((y_segments == 1) | (y_segments == 3), 0, 1)\n\n# Redimensionar X_segments para adaptar a la dimensión de entrada para LSTM\nnum_features = X_segments.shape[2]\nX_segments_reshaped = X_segments.reshape((X_segments.shape[0], X_segments.shape[1], num_features))\n\n# Definir el input layer para todos los sensores\ninput_layer = Input(shape=(sequence_length, num_features))\n\n# Función para crear un bloque convolucional de 1D \ndef conv_block(x, filters, kernel_size, stride, pool_size, pool_stride):\n    x = Conv1D(filters=filters, kernel_size=kernel_size, strides=stride, activation='relu')(x)\n    x = MaxPooling1D(pool_size=pool_size, strides=pool_stride)(x)\n    return x\n\n# Aplicar el bloque convolucional al input\noutput = conv_block(input_layer, filters=16, kernel_size=15, stride=2, pool_size=4, pool_stride=4)\noutput = conv_block(output, filters=32, kernel_size=10, stride=1, pool_size=2, pool_stride=2)\n\n# Conexión completa entre layers\nx = Dense(32, activation='relu')(Flatten()(output))\nx = Dense(16, activation='relu')(x)\n\n# Output layer\noutput_layer = Dense(1, activation='sigmoid')(x)\n\n# Generar el modelo\nmodel_w_binary = Model(inputs=input_layer, outputs=output_layer)\n\n# Imprimir por pantalla el resumen del modelo\nmodel_w_binary.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:02:46.976637Z","iopub.execute_input":"2024-01-14T04:02:46.977043Z","iopub.status.idle":"2024-01-14T04:02:48.733741Z","shell.execute_reply.started":"2024-01-14T04:02:46.977012Z","shell.execute_reply":"2024-01-14T04:02:48.732085Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 700, 6)]          0         \n                                                                 \n conv1d (Conv1D)             (None, 343, 16)           1456      \n                                                                 \n max_pooling1d (MaxPooling1  (None, 85, 16)            0         \n D)                                                              \n                                                                 \n conv1d_1 (Conv1D)           (None, 76, 32)            5152      \n                                                                 \n max_pooling1d_1 (MaxPoolin  (None, 38, 32)            0         \n g1D)                                                            \n                                                                 \n flatten (Flatten)           (None, 1216)              0         \n                                                                 \n dense (Dense)               (None, 32)                38944     \n                                                                 \n dense_1 (Dense)             (None, 16)                528       \n                                                                 \n dense_2 (Dense)             (None, 1)                 17        \n                                                                 \n=================================================================\nTotal params: 46097 (180.07 KB)\nTrainable params: 46097 (180.07 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Normalización de datos\nscaler = StandardScaler()\nX_segments_normalized = scaler.fit_transform(X_segments_reshaped.reshape(-1, num_features)).reshape(X_segments_reshaped.shape)\n\n# Dividir los datos para entrenamiento(80%) y para prueba(20%)\nX_train, X_test, y_train, y_test = train_test_split(X_segments_normalized, y_segments_binary, test_size=0.2, random_state=42)\n\n# Ejecutar el modelo\noptimizer = Adam(lr=0.01)\nmodel_w_binary.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Entrenar el modelo\nmodel_w_binary.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluar la precisión con los datos de prueba\nloss, accuracy = model_w_binary.evaluate(X_test, y_test)\nprint(f'Precisión del modelo de clasificación binaria para datos de muñeca: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:03:51.944666Z","iopub.execute_input":"2024-01-14T04:03:51.945032Z","iopub.status.idle":"2024-01-14T04:13:31.233515Z","shell.execute_reply.started":"2024-01-14T04:03:51.945005Z","shell.execute_reply":"2024-01-14T04:13:31.232416Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/40\n1658/1658 [==============================] - 22s 12ms/step - loss: 0.1049 - accuracy: 0.9599 - val_loss: 0.0371 - val_accuracy: 0.9887\nEpoch 2/40\n1658/1658 [==============================] - 15s 9ms/step - loss: 0.0376 - accuracy: 0.9881 - val_loss: 0.0311 - val_accuracy: 0.9903\nEpoch 3/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 0.0230 - val_accuracy: 0.9932\nEpoch 4/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.0183 - val_accuracy: 0.9946\nEpoch 5/40\n1658/1658 [==============================] - 15s 9ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0271 - val_accuracy: 0.9908\nEpoch 6/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0171 - val_accuracy: 0.9955\nEpoch 7/40\n1658/1658 [==============================] - 15s 9ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0218 - val_accuracy: 0.9921\nEpoch 8/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.0284 - val_accuracy: 0.9917\nEpoch 9/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0220 - val_accuracy: 0.9924\nEpoch 10/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0143 - val_accuracy: 0.9958\nEpoch 11/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0104 - val_accuracy: 0.9971\nEpoch 12/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0114 - val_accuracy: 0.9968\nEpoch 13/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0196 - val_accuracy: 0.9947\nEpoch 14/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0139 - val_accuracy: 0.9964\nEpoch 15/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0187 - val_accuracy: 0.9939\nEpoch 16/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0112 - val_accuracy: 0.9969\nEpoch 17/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0354 - val_accuracy: 0.9903\nEpoch 18/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0351 - val_accuracy: 0.9881\nEpoch 19/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0245 - val_accuracy: 0.9940\nEpoch 20/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0093 - val_accuracy: 0.9972\nEpoch 21/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0161 - val_accuracy: 0.9947\nEpoch 22/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0110 - val_accuracy: 0.9960\nEpoch 23/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0119 - val_accuracy: 0.9965\nEpoch 24/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0118 - val_accuracy: 0.9967\nEpoch 25/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9979\nEpoch 26/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0129 - val_accuracy: 0.9962\nEpoch 27/40\n1658/1658 [==============================] - 13s 8ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0574 - val_accuracy: 0.9923\nEpoch 28/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0141 - val_accuracy: 0.9968\nEpoch 29/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0108 - val_accuracy: 0.9970\nEpoch 30/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0236 - val_accuracy: 0.9939\nEpoch 31/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0151 - val_accuracy: 0.9957\nEpoch 32/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0189 - val_accuracy: 0.9959\nEpoch 33/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0155 - val_accuracy: 0.9971\nEpoch 34/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0227 - val_accuracy: 0.9946\nEpoch 35/40\n1658/1658 [==============================] - 15s 9ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0127 - val_accuracy: 0.9965\nEpoch 36/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0098 - val_accuracy: 0.9973\nEpoch 37/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0273 - val_accuracy: 0.9953\nEpoch 38/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0080 - val_accuracy: 0.9983\nEpoch 39/40\n1658/1658 [==============================] - 14s 8ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0100 - val_accuracy: 0.9974\nEpoch 40/40\n1658/1658 [==============================] - 14s 9ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0172 - val_accuracy: 0.9958\n415/415 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9958\nPrecisión del modelo de clasificación binaria para datos de muñeca: 99.58%\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_binary = (model_w_binary.predict(X_test) > 0.5).astype(int)\ny_true_binary = y_test \n# Calcular F1-score, precisión y recall\nf1 = f1_score(y_true_binary, y_pred_binary)\nprecision = precision_score(y_true_binary, y_pred_binary)\nrecall = recall_score(y_true_binary, y_pred_binary)\nconf_matrix = confusion_matrix(y_true_binary, y_pred_binary)\n\n# Imprimir los resultados\nprint(\"Resultados del modelo de clasificación binaria para datos de muñeca: \")\nprint(f'F1-score: {f1:.4f}')\nprint(f'Precisión: {accuracy:.4f}')\nprint(f'Recall: {recall:.4f}') # Recall es la Tasa de verdaderos positivos\nprint('Matriz de confusión:')\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:14:12.874314Z","iopub.execute_input":"2024-01-14T04:14:12.874730Z","iopub.status.idle":"2024-01-14T04:14:14.694685Z","shell.execute_reply.started":"2024-01-14T04:14:12.874698Z","shell.execute_reply":"2024-01-14T04:14:14.693748Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"415/415 [==============================] - 1s 3ms/step\nResultados del modelo de clasificación binaria para datos de muñeca: \nF1-score: 0.9931\nPrecisión: 0.9958\nRecall: 0.9906\nMatriz de confusión:\n[[9194   18]\n [  38 4011]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ha salido buenos resultados con los parámetros del modelo para los datos de pecho, ahora se modifica otro parámetro batch size para intentar a mejorar más.","metadata":{}},{"cell_type":"code","source":"# Entrenar el modelo\nmodel_w_binary.fit(X_train, y_train, epochs=40, batch_size=16, validation_data=(X_test, y_test))\n\n# Evaluar la precisión con los datos de prueba\nloss, accuracy = model_w_binary.evaluate(X_test, y_test)\nprint(f'Precisión del modelo de clasificación binaria para datos de muñeca: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:15:33.334735Z","iopub.execute_input":"2024-01-14T04:15:33.335179Z","iopub.status.idle":"2024-01-14T04:27:59.814706Z","shell.execute_reply.started":"2024-01-14T04:15:33.335151Z","shell.execute_reply":"2024-01-14T04:27:59.813719Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0177 - val_accuracy: 0.9964\nEpoch 2/40\n3316/3316 [==============================] - 20s 6ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.0333 - val_accuracy: 0.9919\nEpoch 3/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0123 - val_accuracy: 0.9967\nEpoch 4/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0098 - val_accuracy: 0.9978\nEpoch 5/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0120 - val_accuracy: 0.9974\nEpoch 6/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0111 - val_accuracy: 0.9972\nEpoch 7/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0113 - val_accuracy: 0.9977\nEpoch 8/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0136 - val_accuracy: 0.9968\nEpoch 9/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0173 - val_accuracy: 0.9962\nEpoch 10/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0146 - val_accuracy: 0.9968\nEpoch 11/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0206 - val_accuracy: 0.9954\nEpoch 12/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0113 - val_accuracy: 0.9972\nEpoch 13/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0377 - val_accuracy: 0.9945\nEpoch 14/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0133 - val_accuracy: 0.9971\nEpoch 15/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0139 - val_accuracy: 0.9971\nEpoch 16/40\n3316/3316 [==============================] - 18s 6ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0114 - val_accuracy: 0.9971\nEpoch 17/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0141 - val_accuracy: 0.9980\nEpoch 18/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0295 - val_accuracy: 0.9936\nEpoch 19/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0132 - val_accuracy: 0.9973\nEpoch 20/40\n3316/3316 [==============================] - 20s 6ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0119 - val_accuracy: 0.9965\nEpoch 21/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0216 - val_accuracy: 0.9943\nEpoch 22/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0276 - val_accuracy: 0.9921\nEpoch 23/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0124 - val_accuracy: 0.9979\nEpoch 24/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0189 - val_accuracy: 0.9965\nEpoch 25/40\n3316/3316 [==============================] - 18s 6ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0121 - val_accuracy: 0.9976\nEpoch 26/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0172 - val_accuracy: 0.9969\nEpoch 27/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.0129 - val_accuracy: 0.9974\nEpoch 28/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0196 - val_accuracy: 0.9953\nEpoch 29/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0107 - val_accuracy: 0.9977\nEpoch 30/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0120 - val_accuracy: 0.9977\nEpoch 31/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0204 - val_accuracy: 0.9971\nEpoch 32/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0170 - val_accuracy: 0.9980\nEpoch 33/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0144 - val_accuracy: 0.9973\nEpoch 34/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0613 - val_accuracy: 0.9900\nEpoch 35/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.0157 - val_accuracy: 0.9965\nEpoch 36/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0177 - val_accuracy: 0.9976\nEpoch 37/40\n3316/3316 [==============================] - 19s 6ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0100 - val_accuracy: 0.9982\nEpoch 38/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0082 - val_accuracy: 0.9984\nEpoch 39/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0085 - val_accuracy: 0.9977\nEpoch 40/40\n3316/3316 [==============================] - 18s 5ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0111 - val_accuracy: 0.9969\n415/415 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9969\nPrecisión del modelo de clasificación binaria para datos de muñeca: 99.69%\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_binary = (model_w_binary.predict(X_test) > 0.5).astype(int)\ny_true_binary = y_test \n# Calcular F1-score, precisión y recall\nf1 = f1_score(y_true_binary, y_pred_binary)\nprecision = precision_score(y_true_binary, y_pred_binary)\nrecall = recall_score(y_true_binary, y_pred_binary)\nconf_matrix = confusion_matrix(y_true_binary, y_pred_binary)\n\n# Imprimir los resultados\nprint(\"Resultados del modelo de clasificación binaria para datos de muñeca: \")\nprint(f'F1-score: {f1:.4f}')\nprint(f'Precisión: {accuracy:.4f}')\nprint(f'Recall: {recall:.4f}') # Recall es la Tasa de verdaderos positivos\nprint('Matriz de confusión:')\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T04:44:13.046599Z","iopub.execute_input":"2024-01-14T04:44:13.047047Z","iopub.status.idle":"2024-01-14T04:44:14.963585Z","shell.execute_reply.started":"2024-01-14T04:44:13.047017Z","shell.execute_reply":"2024-01-14T04:44:14.962605Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"415/415 [==============================] - 1s 3ms/step\nResultados del modelo de clasificación binaria para datos de muñeca: \nF1-score: 0.9949\nPrecisión: 0.9969\nRecall: 0.9970\nMatriz de confusión:\n[[9183   29]\n [  12 4037]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ha mejorado todavía más, estos resultados son muy bastantes buenos, ahora pasa a la clasificación de tres estados afectivos.","metadata":{}},{"cell_type":"markdown","source":"# Clasificación de tres estados afectivos de los datos de muñuca","metadata":{}},{"cell_type":"code","source":"# Generar un modelo CNN para la clasificaión de tres estados para los datos de muñeca\n# Modificar el modelo anterior para adaptar a la nueva función\nsampling_rate = 700  # Hz\nwindow_time = 1  # segundos\nsequence_length = sampling_rate * window_time\nstep_size = sequence_length // 2\n\nsegments = []\nlabels = []\nfor i in range(0, len(X) - sequence_length, step_size):\n    segment = X[i:i + sequence_length]\n    label = y[i + sequence_length - 1]  \n    segments.append(segment)\n    labels.append(label)\n\n# Convertir a vector \nX_segments = np.array(segments)\ny_segments = np.array(labels)\n\n# Redimensionar X_segments para la entrada para LSTM\nnum_features = X_segments.shape[2]\nX_segments_reshaped = X_segments.reshape((X_segments.shape[0], X_segments.shape[1], num_features))\n\n# One hot encoding, num_classes = 3\ny_segments = y_segments - 1\ny_segments_one_hot = to_categorical(y_segments, num_classes=3) \n\n# Dividir datos para entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X_segments_reshaped, y_segments_one_hot, test_size=0.2, random_state=42)\n\ninput_layer = Input(shape=(sequence_length, num_features))\n\ndef conv_block(x, filters, kernel_size, stride, pool_size, pool_stride):\n    x = Conv1D(filters=filters, kernel_size=kernel_size, strides=stride, activation='relu')(x)\n    x = MaxPooling1D(pool_size=pool_size, strides=pool_stride)(x)\n    return x\n\n# Aplicar el bloque convolucional al input\noutput = conv_block(input_layer, filters=16, kernel_size=15, stride=2, pool_size=4, pool_stride=4)\noutput = conv_block(output, filters=32, kernel_size=10, stride=1, pool_size=2, pool_stride=2)\n\n# Conexión completa entre layers\nx = Dense(32, activation='relu')(Flatten()(output))\nx = Dense(16, activation='relu')(x)\n\n# Output layer para 3 clases, donde 3 es el num_classes\noutput_layer = Dense(3, activation='softmax')(x)\n\n# Generar el modelo para clasificación de 3 estados\nmodel_w_three = Model(inputs=input_layer, outputs=output_layer)\n\noptimizer = Adam(lr=0.01)\nmodel_w_three.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_w_three.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test))\n\nloss, accuracy = model_w_three.evaluate(X_test, y_test)\nprint(f'Precisión del modelo de clasificación de tres estados para datos de muñeca: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:39:29.799395Z","iopub.execute_input":"2024-01-14T17:39:29.799743Z","iopub.status.idle":"2024-01-14T17:46:37.097354Z","shell.execute_reply.started":"2024-01-14T17:39:29.799720Z","shell.execute_reply":"2024-01-14T17:46:37.096350Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.5822 - accuracy: 0.7634 - val_loss: 0.4503 - val_accuracy: 0.8033\nEpoch 2/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.3677 - accuracy: 0.8565 - val_loss: 0.3634 - val_accuracy: 0.8574\nEpoch 3/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.3057 - accuracy: 0.8837 - val_loss: 0.3081 - val_accuracy: 0.8893\nEpoch 4/40\n1658/1658 [==============================] - 12s 7ms/step - loss: 0.2788 - accuracy: 0.8938 - val_loss: 0.2694 - val_accuracy: 0.8906\nEpoch 5/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.2712 - accuracy: 0.8973 - val_loss: 0.2601 - val_accuracy: 0.9050\nEpoch 6/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.2492 - accuracy: 0.9053 - val_loss: 0.2215 - val_accuracy: 0.9202\nEpoch 7/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.2325 - accuracy: 0.9105 - val_loss: 0.2186 - val_accuracy: 0.9162\nEpoch 8/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.2150 - accuracy: 0.9175 - val_loss: 0.2314 - val_accuracy: 0.9124\nEpoch 9/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.2273 - accuracy: 0.9125 - val_loss: 0.2239 - val_accuracy: 0.9201\nEpoch 10/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.2015 - accuracy: 0.9253 - val_loss: 0.1917 - val_accuracy: 0.9321\nEpoch 11/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1972 - accuracy: 0.9255 - val_loss: 0.2246 - val_accuracy: 0.9237\nEpoch 12/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.2204 - accuracy: 0.9182 - val_loss: 0.2904 - val_accuracy: 0.8911\nEpoch 13/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1881 - accuracy: 0.9293 - val_loss: 0.2371 - val_accuracy: 0.9110\nEpoch 14/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1946 - accuracy: 0.9280 - val_loss: 0.1768 - val_accuracy: 0.9326\nEpoch 15/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1887 - accuracy: 0.9283 - val_loss: 0.2158 - val_accuracy: 0.9189\nEpoch 16/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1794 - accuracy: 0.9312 - val_loss: 0.2278 - val_accuracy: 0.9113\nEpoch 17/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1761 - accuracy: 0.9344 - val_loss: 0.1786 - val_accuracy: 0.9389\nEpoch 18/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1649 - accuracy: 0.9383 - val_loss: 0.1843 - val_accuracy: 0.9326\nEpoch 19/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1639 - accuracy: 0.9387 - val_loss: 0.1830 - val_accuracy: 0.9396\nEpoch 20/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1518 - accuracy: 0.9434 - val_loss: 0.1560 - val_accuracy: 0.9450\nEpoch 21/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1569 - accuracy: 0.9438 - val_loss: 0.1845 - val_accuracy: 0.9342\nEpoch 22/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1400 - accuracy: 0.9481 - val_loss: 0.1936 - val_accuracy: 0.9373\nEpoch 23/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1462 - accuracy: 0.9462 - val_loss: 0.1679 - val_accuracy: 0.9394\nEpoch 24/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1477 - accuracy: 0.9447 - val_loss: 0.1619 - val_accuracy: 0.9461\nEpoch 25/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1409 - accuracy: 0.9478 - val_loss: 0.1562 - val_accuracy: 0.9470\nEpoch 26/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1334 - accuracy: 0.9514 - val_loss: 0.1316 - val_accuracy: 0.9532\nEpoch 27/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1343 - accuracy: 0.9513 - val_loss: 0.1773 - val_accuracy: 0.9435\nEpoch 28/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1440 - accuracy: 0.9458 - val_loss: 0.2124 - val_accuracy: 0.9127\nEpoch 29/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1574 - accuracy: 0.9424 - val_loss: 0.1910 - val_accuracy: 0.9419\nEpoch 30/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1604 - accuracy: 0.9451 - val_loss: 0.1544 - val_accuracy: 0.9526\nEpoch 31/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1280 - accuracy: 0.9523 - val_loss: 0.1380 - val_accuracy: 0.9551\nEpoch 32/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1258 - accuracy: 0.9533 - val_loss: 0.1297 - val_accuracy: 0.9569\nEpoch 33/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1168 - accuracy: 0.9564 - val_loss: 0.1490 - val_accuracy: 0.9509\nEpoch 34/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1177 - accuracy: 0.9569 - val_loss: 0.1614 - val_accuracy: 0.9523\nEpoch 35/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1226 - accuracy: 0.9567 - val_loss: 0.1635 - val_accuracy: 0.9511\nEpoch 36/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1163 - accuracy: 0.9575 - val_loss: 0.1790 - val_accuracy: 0.9493\nEpoch 37/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1189 - accuracy: 0.9562 - val_loss: 0.1441 - val_accuracy: 0.9505\nEpoch 38/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1152 - accuracy: 0.9575 - val_loss: 0.1599 - val_accuracy: 0.9514\nEpoch 39/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1153 - accuracy: 0.9578 - val_loss: 0.1774 - val_accuracy: 0.9427\nEpoch 40/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1131 - accuracy: 0.9584 - val_loss: 0.1338 - val_accuracy: 0.9590\n415/415 [==============================] - 1s 2ms/step - loss: 0.1338 - accuracy: 0.9590\nPrecisión del modelo de clasificación de tres estados para datos de muñeca: 95.90%\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_three = np.argmax(model_w_three.predict(X_test), axis=1)\ny_true_three = np.argmax(y_test, axis=1)\n\nf1 = f1_score(y_true_three, y_pred_three, average='weighted')\nprecision = precision_score(y_true_three, y_pred_three, average='weighted')\nrecall = recall_score(y_true_three, y_pred_three, average='weighted')\n\n# Imprimir los reesultados\nprint(\"Resultados del modelo de clasificación de tres estados para datos de muñeca: \")\nprint(f'F1-score: {f1:.4f}')\nprint(f'Precisión: {accuracy:.4f}')\nprint(f'Recall: {recall:.4f}')\n\n# Imprimir la matriz de confusión\nconf_matrix = confusion_matrix(y_true_three, y_pred_three)\nprint('Matriz de confusión:')\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:49:02.984581Z","iopub.execute_input":"2024-01-14T17:49:02.984937Z","iopub.status.idle":"2024-01-14T17:49:04.389531Z","shell.execute_reply.started":"2024-01-14T17:49:02.984913Z","shell.execute_reply":"2024-01-14T17:49:04.388675Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"415/415 [==============================] - 1s 2ms/step\nResultados del modelo de clasificación de tres estados para datos de muñeca: \nF1-score: 0.9591\nPrecisión: 0.9590\nRecall: 0.9590\nMatriz de confusión:\n[[6707  111  173]\n [ 114 3916   19]\n [ 102   25 2094]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ahora se modifica el batch size a 16 como el modelo de clasificación binaria.","metadata":{}},{"cell_type":"code","source":"# Entrenar el modelo con batch size=16\nmodel_w_three.fit(X_train, y_train, epochs=40, batch_size=16, validation_data=(X_test, y_test))\n\n# Evaluar la precisión con los datos de prueba\nloss, accuracy = model_w_three.evaluate(X_test, y_test)\nprint(f'Precisión del modelo de clasificación de tres estados para datos de muñeca: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:49:30.066424Z","iopub.execute_input":"2024-01-14T17:49:30.066790Z","iopub.status.idle":"2024-01-14T17:58:56.231304Z","shell.execute_reply.started":"2024-01-14T17:49:30.066764Z","shell.execute_reply":"2024-01-14T17:58:56.230659Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1601 - accuracy: 0.9431 - val_loss: 0.1425 - val_accuracy: 0.9568\nEpoch 2/40\n3316/3316 [==============================] - 15s 5ms/step - loss: 0.1474 - accuracy: 0.9479 - val_loss: 0.2057 - val_accuracy: 0.9305\nEpoch 3/40\n3316/3316 [==============================] - 15s 5ms/step - loss: 0.1481 - accuracy: 0.9480 - val_loss: 0.1932 - val_accuracy: 0.9486\nEpoch 4/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1482 - accuracy: 0.9483 - val_loss: 0.1984 - val_accuracy: 0.9382\nEpoch 5/40\n3316/3316 [==============================] - 15s 5ms/step - loss: 0.1652 - accuracy: 0.9458 - val_loss: 0.1534 - val_accuracy: 0.9465\nEpoch 6/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1362 - accuracy: 0.9522 - val_loss: 0.1893 - val_accuracy: 0.9390\nEpoch 7/40\n3316/3316 [==============================] - 15s 5ms/step - loss: 0.1487 - accuracy: 0.9492 - val_loss: 0.1954 - val_accuracy: 0.9390\nEpoch 8/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1370 - accuracy: 0.9505 - val_loss: 0.1766 - val_accuracy: 0.9477\nEpoch 9/40\n3316/3316 [==============================] - 15s 4ms/step - loss: 0.1566 - accuracy: 0.9484 - val_loss: 0.1657 - val_accuracy: 0.9485\nEpoch 10/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1417 - accuracy: 0.9515 - val_loss: 0.1501 - val_accuracy: 0.9558\nEpoch 11/40\n3316/3316 [==============================] - 15s 4ms/step - loss: 0.1441 - accuracy: 0.9520 - val_loss: 0.1887 - val_accuracy: 0.9454\nEpoch 12/40\n3316/3316 [==============================] - 15s 4ms/step - loss: 0.1361 - accuracy: 0.9535 - val_loss: 0.2636 - val_accuracy: 0.9228\nEpoch 13/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1669 - accuracy: 0.9460 - val_loss: 0.1480 - val_accuracy: 0.9534\nEpoch 14/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1480 - accuracy: 0.9507 - val_loss: 0.2628 - val_accuracy: 0.9200\nEpoch 15/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1347 - accuracy: 0.9546 - val_loss: 0.1804 - val_accuracy: 0.9486\nEpoch 16/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1413 - accuracy: 0.9525 - val_loss: 0.2291 - val_accuracy: 0.9323\nEpoch 17/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1490 - accuracy: 0.9505 - val_loss: 0.2004 - val_accuracy: 0.9257\nEpoch 18/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1393 - accuracy: 0.9532 - val_loss: 0.1783 - val_accuracy: 0.9440\nEpoch 19/40\n3316/3316 [==============================] - 13s 4ms/step - loss: 0.1413 - accuracy: 0.9553 - val_loss: 0.1840 - val_accuracy: 0.9416\nEpoch 20/40\n3316/3316 [==============================] - 13s 4ms/step - loss: 0.1397 - accuracy: 0.9541 - val_loss: 0.1596 - val_accuracy: 0.9578\nEpoch 21/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1487 - accuracy: 0.9518 - val_loss: 0.1805 - val_accuracy: 0.9494\nEpoch 22/40\n3316/3316 [==============================] - 15s 4ms/step - loss: 0.1406 - accuracy: 0.9546 - val_loss: 0.1676 - val_accuracy: 0.9516\nEpoch 23/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.2630 - accuracy: 0.9308 - val_loss: 0.2914 - val_accuracy: 0.9183\nEpoch 24/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1926 - accuracy: 0.9400 - val_loss: 0.1813 - val_accuracy: 0.9498\nEpoch 25/40\n3316/3316 [==============================] - 15s 5ms/step - loss: 0.1633 - accuracy: 0.9461 - val_loss: 0.2021 - val_accuracy: 0.9435\nEpoch 26/40\n3316/3316 [==============================] - 15s 4ms/step - loss: 0.1551 - accuracy: 0.9498 - val_loss: 0.1584 - val_accuracy: 0.9581\nEpoch 27/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1363 - accuracy: 0.9560 - val_loss: 0.1916 - val_accuracy: 0.9413\nEpoch 28/40\n3316/3316 [==============================] - 13s 4ms/step - loss: 0.1313 - accuracy: 0.9561 - val_loss: 0.1410 - val_accuracy: 0.9606\nEpoch 29/40\n3316/3316 [==============================] - 16s 5ms/step - loss: 0.1498 - accuracy: 0.9536 - val_loss: 0.4931 - val_accuracy: 0.8111\nEpoch 30/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.2144 - accuracy: 0.9315 - val_loss: 0.1733 - val_accuracy: 0.9460\nEpoch 31/40\n3316/3316 [==============================] - 13s 4ms/step - loss: 0.1833 - accuracy: 0.9443 - val_loss: 0.5531 - val_accuracy: 0.9137\nEpoch 32/40\n3316/3316 [==============================] - 15s 5ms/step - loss: 0.1486 - accuracy: 0.9517 - val_loss: 0.2366 - val_accuracy: 0.9483\nEpoch 33/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1400 - accuracy: 0.9567 - val_loss: 0.1729 - val_accuracy: 0.9612\nEpoch 34/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1374 - accuracy: 0.9556 - val_loss: 0.1974 - val_accuracy: 0.9477\nEpoch 35/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1837 - accuracy: 0.9506 - val_loss: 0.1510 - val_accuracy: 0.9596\nEpoch 36/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1365 - accuracy: 0.9597 - val_loss: 0.2009 - val_accuracy: 0.9535\nEpoch 37/40\n3316/3316 [==============================] - 15s 5ms/step - loss: 0.1283 - accuracy: 0.9619 - val_loss: 0.1702 - val_accuracy: 0.9551\nEpoch 38/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1324 - accuracy: 0.9598 - val_loss: 0.1680 - val_accuracy: 0.9642\nEpoch 39/40\n3316/3316 [==============================] - 13s 4ms/step - loss: 0.1268 - accuracy: 0.9634 - val_loss: 0.1706 - val_accuracy: 0.9591\nEpoch 40/40\n3316/3316 [==============================] - 14s 4ms/step - loss: 0.1466 - accuracy: 0.9597 - val_loss: 0.2295 - val_accuracy: 0.9354\n415/415 [==============================] - 1s 3ms/step - loss: 0.2295 - accuracy: 0.9354\nPrecisión del modelo de clasificación de tres estados para datos de muñeca: 93.54%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ha empeorado los resultado, se modifica otros parámetros.","metadata":{}},{"cell_type":"code","source":"# Entrenar el modelo con lr=0,001\noptimizer = Adam(lr=0.001)\nmodel_w_three.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_w_three.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluar la precisión con los datos de prueba\nloss, accuracy = model_w_three.evaluate(X_test, y_test)\nprint(f'Precisión del modelo de clasificación de tres estados para datos de muñeca: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T16:35:40.694786Z","iopub.execute_input":"2024-01-14T16:35:40.695123Z","iopub.status.idle":"2024-01-14T16:42:46.523244Z","shell.execute_reply.started":"2024-01-14T16:35:40.695100Z","shell.execute_reply":"2024-01-14T16:42:46.522341Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/40\n1658/1658 [==============================] - 12s 7ms/step - loss: 0.1143 - accuracy: 0.9637 - val_loss: 0.1943 - val_accuracy: 0.9414\nEpoch 2/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1186 - accuracy: 0.9610 - val_loss: 0.1281 - val_accuracy: 0.9587\nEpoch 3/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1012 - accuracy: 0.9643 - val_loss: 0.1155 - val_accuracy: 0.9650\nEpoch 4/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1097 - accuracy: 0.9662 - val_loss: 0.2529 - val_accuracy: 0.9207\nEpoch 5/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1075 - accuracy: 0.9661 - val_loss: 0.1145 - val_accuracy: 0.9692\nEpoch 6/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.0987 - accuracy: 0.9700 - val_loss: 0.1157 - val_accuracy: 0.9694\nEpoch 7/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1651 - accuracy: 0.9549 - val_loss: 0.1626 - val_accuracy: 0.9544\nEpoch 8/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.2035 - accuracy: 0.9421 - val_loss: 0.1853 - val_accuracy: 0.9442\nEpoch 9/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1167 - accuracy: 0.9628 - val_loss: 0.1494 - val_accuracy: 0.9576\nEpoch 10/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1050 - accuracy: 0.9670 - val_loss: 0.1185 - val_accuracy: 0.9634\nEpoch 11/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1092 - accuracy: 0.9669 - val_loss: 0.1275 - val_accuracy: 0.9617\nEpoch 12/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1055 - accuracy: 0.9682 - val_loss: 0.1597 - val_accuracy: 0.9623\nEpoch 13/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1039 - accuracy: 0.9677 - val_loss: 0.1313 - val_accuracy: 0.9638\nEpoch 14/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1003 - accuracy: 0.9674 - val_loss: 0.1943 - val_accuracy: 0.9379\nEpoch 15/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1224 - accuracy: 0.9591 - val_loss: 0.1695 - val_accuracy: 0.9560\nEpoch 16/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1028 - accuracy: 0.9682 - val_loss: 0.1258 - val_accuracy: 0.9682\nEpoch 17/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0839 - accuracy: 0.9735 - val_loss: 0.1049 - val_accuracy: 0.9714\nEpoch 18/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.0921 - accuracy: 0.9715 - val_loss: 0.1304 - val_accuracy: 0.9640\nEpoch 19/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.1179 - accuracy: 0.9681 - val_loss: 0.1287 - val_accuracy: 0.9668\nEpoch 20/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0875 - accuracy: 0.9732 - val_loss: 0.1336 - val_accuracy: 0.9652\nEpoch 21/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.0971 - accuracy: 0.9699 - val_loss: 0.1165 - val_accuracy: 0.9709\nEpoch 22/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1166 - accuracy: 0.9635 - val_loss: 0.1603 - val_accuracy: 0.9400\nEpoch 23/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0998 - accuracy: 0.9679 - val_loss: 0.1357 - val_accuracy: 0.9545\nEpoch 24/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.0957 - accuracy: 0.9709 - val_loss: 0.1667 - val_accuracy: 0.9678\nEpoch 25/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1036 - accuracy: 0.9684 - val_loss: 0.1107 - val_accuracy: 0.9659\nEpoch 26/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1012 - accuracy: 0.9687 - val_loss: 0.1400 - val_accuracy: 0.9658\nEpoch 27/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1060 - accuracy: 0.9710 - val_loss: 0.1520 - val_accuracy: 0.9603\nEpoch 28/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0856 - accuracy: 0.9744 - val_loss: 0.1474 - val_accuracy: 0.9611\nEpoch 29/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0857 - accuracy: 0.9735 - val_loss: 0.1517 - val_accuracy: 0.9585\nEpoch 30/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.0962 - accuracy: 0.9720 - val_loss: 0.1216 - val_accuracy: 0.9685\nEpoch 31/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0880 - accuracy: 0.9726 - val_loss: 0.1742 - val_accuracy: 0.9642\nEpoch 32/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.0717 - accuracy: 0.9765 - val_loss: 0.1122 - val_accuracy: 0.9713\nEpoch 33/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1331 - accuracy: 0.9582 - val_loss: 0.1545 - val_accuracy: 0.9639\nEpoch 34/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0929 - accuracy: 0.9724 - val_loss: 0.1261 - val_accuracy: 0.9680\nEpoch 35/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0876 - accuracy: 0.9745 - val_loss: 0.1234 - val_accuracy: 0.9685\nEpoch 36/40\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.0819 - accuracy: 0.9757 - val_loss: 0.1173 - val_accuracy: 0.9670\nEpoch 37/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.0970 - accuracy: 0.9715 - val_loss: 0.1302 - val_accuracy: 0.9713\nEpoch 38/40\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.1079 - accuracy: 0.9710 - val_loss: 0.1282 - val_accuracy: 0.9708\nEpoch 39/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.0699 - accuracy: 0.9797 - val_loss: 0.1311 - val_accuracy: 0.9704\nEpoch 40/40\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.1671 - accuracy: 0.9587 - val_loss: 0.2204 - val_accuracy: 0.9321\n415/415 [==============================] - 1s 2ms/step - loss: 0.2204 - accuracy: 0.9321\nPrecisión del modelo de clasificación de tres estados para datos de muñeca: 93.21%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ha empeorado todavía, se añade 2 capas de dropout para ver si mejoraría.","metadata":{}},{"cell_type":"code","source":"# Mejorar el modelo añadir 2 capas dropout\nx = Dense(32, activation='relu')(Flatten()(output))\nx = Dropout(0.5)(x)\nx = Dense(16, activation='relu')(x)\nx = Dropout(0.5)(x)\n\n# Output layer para 3 clases, donde 3 es el num_classes\noutput_layer = Dense(3, activation='softmax')(x)\n\n# Generar el modelo para clasificación de 3 estados\nmodel_w_three_2 = Model(inputs=input_layer, outputs=output_layer)\n\noptimizer = Adam(lr=0.01)\nmodel_w_three_2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_w_three_2.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n\nloss, accuracy = model_w_three_2.evaluate(X_test, y_test)\nprint(f'Precisión del modelo de clasificación de tres estados para datos de muñeca: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:08:08.257770Z","iopub.execute_input":"2024-01-14T17:08:08.258114Z","iopub.status.idle":"2024-01-14T17:11:44.592044Z","shell.execute_reply.started":"2024-01-14T17:08:08.258089Z","shell.execute_reply":"2024-01-14T17:11:44.591189Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/20\n1658/1658 [==============================] - 12s 7ms/step - loss: 6.3643 - accuracy: 0.5280 - val_loss: 1.0011 - val_accuracy: 0.5272\nEpoch 2/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.9997 - accuracy: 0.5323 - val_loss: 0.9993 - val_accuracy: 0.5273\nEpoch 3/20\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.9970 - accuracy: 0.5323 - val_loss: 0.9992 - val_accuracy: 0.5273\nEpoch 4/20\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.9968 - accuracy: 0.5323 - val_loss: 0.9989 - val_accuracy: 0.5273\nEpoch 5/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 1.0016 - accuracy: 0.5322 - val_loss: 0.9990 - val_accuracy: 0.5272\nEpoch 6/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 1.0230 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 7/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9990 - val_accuracy: 0.5272\nEpoch 8/20\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.9973 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 9/20\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 10/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 11/20\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.9967 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 12/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9992 - val_accuracy: 0.5272\nEpoch 13/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 14/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.9967 - accuracy: 0.5322 - val_loss: 0.9992 - val_accuracy: 0.5272\nEpoch 15/20\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9990 - val_accuracy: 0.5272\nEpoch 16/20\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.9967 - accuracy: 0.5322 - val_loss: 0.9992 - val_accuracy: 0.5272\nEpoch 17/20\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 18/20\n1658/1658 [==============================] - 10s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9990 - val_accuracy: 0.5272\nEpoch 19/20\n1658/1658 [==============================] - 11s 6ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\nEpoch 20/20\n1658/1658 [==============================] - 11s 7ms/step - loss: 0.9968 - accuracy: 0.5322 - val_loss: 0.9991 - val_accuracy: 0.5272\n415/415 [==============================] - 1s 2ms/step - loss: 0.9991 - accuracy: 0.5272\nPrecisión del modelo de clasificación de tres estados para datos de muñeca: 52.72%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Ha empeorado mucho, así que añadir capa dropout no es el camino. Ahora comprueba con eliminir una capa de output.","metadata":{}},{"cell_type":"code","source":"# Aplicar una capa de output del bloque convolucional al input\noutput = conv_block(input_layer, filters=16, kernel_size=15, stride=2, pool_size=4, pool_stride=4)\n\n# Conexión completa entre layers\nx = Dense(32, activation='relu')(Flatten()(output))\nx = Dense(16, activation='relu')(x)\n\n# Output layer para 3 clases, donde 3 es el num_classes\noutput_layer = Dense(3, activation='softmax')(x)\n\n# Generar el modelo para clasificación de 3 estados\nmodel_w_three_3 = Model(inputs=input_layer, outputs=output_layer)\n\noptimizer = Adam(lr=0.01)\nmodel_w_three_3.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel_w_three_3.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test))\n\nloss, accuracy = model_w_three_3.evaluate(X_test, y_test)\nprint(f'Precisión del modelo de clasificación de tres estados para datos de muñeca: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:18:38.335902Z","iopub.execute_input":"2024-01-14T17:18:38.336294Z","iopub.status.idle":"2024-01-14T17:23:47.089163Z","shell.execute_reply.started":"2024-01-14T17:18:38.336269Z","shell.execute_reply":"2024-01-14T17:23:47.088022Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/40\n1658/1658 [==============================] - 9s 5ms/step - loss: 0.6928 - accuracy: 0.7339 - val_loss: 0.6068 - val_accuracy: 0.7582\nEpoch 2/40\n1658/1658 [==============================] - 7s 5ms/step - loss: 0.4910 - accuracy: 0.8152 - val_loss: 0.4720 - val_accuracy: 0.8134\nEpoch 3/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.4358 - accuracy: 0.8379 - val_loss: 0.4430 - val_accuracy: 0.8334\nEpoch 4/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.4028 - accuracy: 0.8496 - val_loss: 0.3819 - val_accuracy: 0.8343\nEpoch 5/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.3747 - accuracy: 0.8570 - val_loss: 0.3782 - val_accuracy: 0.8579\nEpoch 6/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.3691 - accuracy: 0.8616 - val_loss: 0.3442 - val_accuracy: 0.8697\nEpoch 7/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.3507 - accuracy: 0.8673 - val_loss: 0.3193 - val_accuracy: 0.8778\nEpoch 8/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.3371 - accuracy: 0.8712 - val_loss: 0.3448 - val_accuracy: 0.8610\nEpoch 9/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.3282 - accuracy: 0.8756 - val_loss: 0.3531 - val_accuracy: 0.8509\nEpoch 10/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.3139 - accuracy: 0.8823 - val_loss: 0.3128 - val_accuracy: 0.8800\nEpoch 11/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.3143 - accuracy: 0.8822 - val_loss: 0.3058 - val_accuracy: 0.8768\nEpoch 12/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.3037 - accuracy: 0.8856 - val_loss: 0.2789 - val_accuracy: 0.8933\nEpoch 13/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2928 - accuracy: 0.8909 - val_loss: 0.3211 - val_accuracy: 0.8751\nEpoch 14/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2849 - accuracy: 0.8954 - val_loss: 0.2732 - val_accuracy: 0.9006\nEpoch 15/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2811 - accuracy: 0.8976 - val_loss: 0.2990 - val_accuracy: 0.8872\nEpoch 16/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2816 - accuracy: 0.8968 - val_loss: 0.3084 - val_accuracy: 0.8782\nEpoch 17/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2832 - accuracy: 0.8964 - val_loss: 0.2779 - val_accuracy: 0.9020\nEpoch 18/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2702 - accuracy: 0.9011 - val_loss: 0.2803 - val_accuracy: 0.8987\nEpoch 19/40\n1658/1658 [==============================] - 7s 5ms/step - loss: 0.2666 - accuracy: 0.9038 - val_loss: 0.2720 - val_accuracy: 0.9039\nEpoch 20/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2605 - accuracy: 0.9063 - val_loss: 0.2666 - val_accuracy: 0.9006\nEpoch 21/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2627 - accuracy: 0.9050 - val_loss: 0.2769 - val_accuracy: 0.9008\nEpoch 22/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2547 - accuracy: 0.9074 - val_loss: 0.2679 - val_accuracy: 0.9059\nEpoch 23/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2577 - accuracy: 0.9066 - val_loss: 0.2774 - val_accuracy: 0.8940\nEpoch 24/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2545 - accuracy: 0.9077 - val_loss: 0.2906 - val_accuracy: 0.8993\nEpoch 25/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2549 - accuracy: 0.9089 - val_loss: 0.2525 - val_accuracy: 0.9148\nEpoch 26/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2523 - accuracy: 0.9085 - val_loss: 0.2658 - val_accuracy: 0.9021\nEpoch 27/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2477 - accuracy: 0.9114 - val_loss: 0.2736 - val_accuracy: 0.9030\nEpoch 28/40\n1658/1658 [==============================] - 7s 5ms/step - loss: 0.2450 - accuracy: 0.9122 - val_loss: 0.2468 - val_accuracy: 0.9134\nEpoch 29/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2412 - accuracy: 0.9144 - val_loss: 0.2768 - val_accuracy: 0.9093\nEpoch 30/40\n1658/1658 [==============================] - 7s 5ms/step - loss: 0.2427 - accuracy: 0.9138 - val_loss: 0.2337 - val_accuracy: 0.9155\nEpoch 31/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2405 - accuracy: 0.9127 - val_loss: 0.2624 - val_accuracy: 0.9091\nEpoch 32/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2368 - accuracy: 0.9146 - val_loss: 0.2516 - val_accuracy: 0.9095\nEpoch 33/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2420 - accuracy: 0.9123 - val_loss: 0.2374 - val_accuracy: 0.9150\nEpoch 34/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2427 - accuracy: 0.9140 - val_loss: 0.2647 - val_accuracy: 0.9039\nEpoch 35/40\n1658/1658 [==============================] - 7s 5ms/step - loss: 0.2425 - accuracy: 0.9142 - val_loss: 0.3200 - val_accuracy: 0.8836\nEpoch 36/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2332 - accuracy: 0.9172 - val_loss: 0.2313 - val_accuracy: 0.9218\nEpoch 37/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2365 - accuracy: 0.9158 - val_loss: 0.2652 - val_accuracy: 0.9100\nEpoch 38/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2368 - accuracy: 0.9154 - val_loss: 0.2648 - val_accuracy: 0.9023\nEpoch 39/40\n1658/1658 [==============================] - 8s 5ms/step - loss: 0.2315 - accuracy: 0.9168 - val_loss: 0.2811 - val_accuracy: 0.8989\nEpoch 40/40\n1658/1658 [==============================] - 7s 4ms/step - loss: 0.2327 - accuracy: 0.9166 - val_loss: 0.2584 - val_accuracy: 0.9108\n415/415 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.9108\nPrecisión del modelo de clasificación de tres estados para datos de muñeca: 91.08%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"No se ha mejorado más, los resultados conseguidos con el modelo inicial con los mismos parámetros que el modelo de datos de pecho son los mejores, es decir, con una precisión de 95,90%. ","metadata":{}}]}